version: '3'

services:
  # Vector Database (Chroma)
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "8000:8000"
    restart: unless-stopped

  # LLM Service (Ollama)
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # RAG Engine v√† API Backend
  rag-api:
    build:
      context: ./rag-service
      dockerfile: Dockerfile
    depends_on:
      - chroma
      - ollama
    ports:
      - "8080:8080"
    environment:
      - CHROMA_HOST=chroma
      - CHROMA_PORT=8000
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST}
      - ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT}
      - ELASTICSEARCH_USER=${ELASTICSEARCH_USER}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
    restart: unless-stopped

  # Web Interface
  web-ui:
    build:
      context: ./web-ui
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://rag-api:8080
    depends_on:
      - rag-api
    restart: unless-stopped

volumes:
  chroma_data:
  ollama_models:
